{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features, labels = make_classification(n_samples=1000, n_classes=4, n_informative=35\n",
    "                                       , n_features=40, class_sep=2.0)\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ID3:\n",
    "    # The node for the ID3 decision tree\n",
    "    class TreeNode:\n",
    "        def __init__(self, attrId = -1, matchesLevel = [], children = [], returnVal = None):\n",
    "            # The index of the column to split out\n",
    "            self.attrId = attrId\n",
    "            \n",
    "            # List of one parameter lambda functions that return True/False \n",
    "            # based on whether the parameter matches the branch\n",
    "            self.matchesLevel = matchesLevel\n",
    "            \n",
    "            # List of child TreeNodes\n",
    "            self.children = children\n",
    "            \n",
    "            # The return value for this node, the class label if it's a leaf node, None if it is not\n",
    "            self.returnVal = returnVal\n",
    "            \n",
    "    def __init__(self):\n",
    "        self.rootNode = None\n",
    "    \n",
    "    # Determines the best attribute to split by given features X and labels y\n",
    "    # Currently, this function assumes that X is numeric, and therefore computes\n",
    "    # split points by taking the average of each pair of ordered unique values\n",
    "    # Returns the column index of the best attribute and a list of functions\n",
    "    # that return True/False based on whether the attribute fits the split\n",
    "    def determineBestAttribute(X, y):\n",
    "        \n",
    "        # Computes the information in the labels\n",
    "        def computeInfo(y):\n",
    "            yVals = np.unique(y)\n",
    "            infoComps = np.zeros(len(yVals))\n",
    "            total = len(y)\n",
    "            for i in range(len(yVals)):\n",
    "                count = len(y[y == yVals[i]])\n",
    "                component = -(count / total) * np.log2(count / total)\n",
    "                infoComps[i] = component\n",
    "            return infoComps.sum()\n",
    "            \n",
    "        # array of information gain/other metric for each column, initialized to zeros\n",
    "        metric = np.zeros(X.shape[1])\n",
    "        \n",
    "        # list of list of functions that return True/False based on level of attribute, initially empty\n",
    "        matchFuncs = []\n",
    "        \n",
    "        # Compute best information and match functions for each column\n",
    "        for i in range(X.shape[1]):\n",
    "            # create split points for the column\n",
    "            uniqueVals = np.unique(X[:, i])\n",
    "            splitPoints = (uniqueVals[:-1] + uniqueVals[1:]) / 2\n",
    "            \n",
    "            # Iterate through the split points, find the best one for this specific column\n",
    "            bestMetric = None\n",
    "            splitFuncs = None\n",
    "            \n",
    "            for sp in splitPoints:\n",
    "                matchFunc1 = lambda x, sp=sp: x < sp\n",
    "                matchFunc2 = lambda x, sp=sp: x >= sp\n",
    "                y1 = y[matchFunc1(X[:, i])]\n",
    "                y2 = y[matchFunc2(X[:, i])]\n",
    "                info1 = computeInfo(y1)\n",
    "                info2 = computeInfo(y2)\n",
    "                m = len(y1) / len(y) * info1 + len(y2) / len(y) * info2\n",
    "                if bestMetric == None or m < bestMetric:\n",
    "                    splitFuncs = [matchFunc1, matchFunc2]\n",
    "                    bestMetric = m\n",
    "\n",
    "            # save the best metric (ie information gain) for the column and the match function for it\n",
    "            metric[i] = bestMetric\n",
    "            matchFuncs.append(splitFuncs)\n",
    "\n",
    "        # Find the best attribute/match function from all the columns\n",
    "        bestAttr = np.argmin(metric)\n",
    "        return bestAttr, matchFuncs[bestAttr]\n",
    "    \n",
    "    # Creates a node in the tree with feature set X and labels y\n",
    "    def createNode(X, y):\n",
    "        # If there is only 1 unique label, predict that label\n",
    "        if len(np.unique(y)) == 1:\n",
    "            return ID3.TreeNode(returnVal = y[0])\n",
    "        \n",
    "        # No features left, return the most abundant class in y\n",
    "        if X.shape[1] == 0:\n",
    "            return ID3.TreeNode(returnVal = mode(y).mode[0])\n",
    "        \n",
    "        # Determine the best attribute to split the dataset by and how to split it\n",
    "        bestAttr, matchesLevel = ID3.determineBestAttribute(X, y)\n",
    "        \n",
    "        # Create the children nodes with subsets of the features/labels\n",
    "        children = []\n",
    "        for i in range(len(matchesLevel)):\n",
    "            children.append(\n",
    "                ID3.createNode(\n",
    "                    np.delete(X[matchesLevel[i](X[:, bestAttr]), :], bestAttr, 1), y[matchesLevel[i](X[:, bestAttr])]\n",
    "                )\n",
    "            )\n",
    "        return ID3.TreeNode(attrId = bestAttr, matchesLevel = matchesLevel, children = children)\n",
    "\n",
    "    # Fits the ID3 decision tree with feature set X and labels y\n",
    "    def fit(self, X, y):\n",
    "        self.rootNode = ID3.createNode(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.rootNode == None:\n",
    "            return None\n",
    "        # Given a row from the feature set, predict the label\n",
    "        def predictTuple(x, node = self.rootNode):\n",
    "            if node.returnVal != None:\n",
    "                return node.returnVal\n",
    "            for i in range(len(node.matchesLevel)):\n",
    "                f = node.matchesLevel[i]\n",
    "                if f(x[node.attrId]):\n",
    "                    return predictTuple(np.delete(x, node.attrId), node.children[i])\n",
    "            # Attribute has a new value not seen before by the tree, returning None for the label\n",
    "            return None\n",
    "        \n",
    "        # Iterate through all the rows, predict the label for each\n",
    "        preds = np.zeros(X.shape[0])\n",
    "        for i in range(X.shape[0]):\n",
    "            preds[i] = predictTuple(X[i, :])\n",
    "        return preds\n",
    "    \n",
    "    # For debugging\n",
    "    def printTreeBreadth(self):\n",
    "        strStack = []\n",
    "        nodeStack = [(0, self.rootNode)]\n",
    "        while len(nodeStack) != 0:\n",
    "            level, n = nodeStack.pop(0)\n",
    "            for i in range(level):\n",
    "                print(\"  \", end=\"\")\n",
    "            if n.returnVal != None:\n",
    "                print(\"Return val of\", n.returnVal)\n",
    "                continue\n",
    "            print(\"Attribute\", n.attrId)\n",
    "            for c in n.children:\n",
    "                nodeStack.append((level + 1, c))\n",
    "        \n",
    "    def printTreeDepth(self):\n",
    "        def printNode(n = self.rootNode, level = 0):\n",
    "            for i in range(level):\n",
    "                print(\"  \", end = \"\")\n",
    "            if n.returnVal != None:\n",
    "                print(\"Return val of\", n.returnVal)\n",
    "                return\n",
    "            print(\"Attribute\", n.attrId)\n",
    "            for c in n.children:\n",
    "                printNode(c, level + 1)\n",
    "        printNode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.66      0.63        56\n",
      "          1       0.49      0.40      0.44        57\n",
      "          2       0.62      0.66      0.64        73\n",
      "          3       0.56      0.56      0.56        64\n",
      "\n",
      "avg / total       0.57      0.58      0.57       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "id3 = ID3()\n",
    "id3.fit(features_train, labels_train)\n",
    "predictions = id3.predict(features_test)\n",
    "print(classification_report(labels_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.57      0.62      0.60        56\n",
      "          1       0.43      0.40      0.42        57\n",
      "          2       0.59      0.56      0.57        73\n",
      "          3       0.55      0.56      0.55        64\n",
      "\n",
      "avg / total       0.54      0.54      0.54       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtc = DecisionTreeClassifier(criterion=\"entropy\")\n",
    "dtc = dtc.fit(features_train, labels_train)\n",
    "dtc_prediction = dtc.predict(features_test)\n",
    "\n",
    "print(classification_report(labels_test, dtc_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
