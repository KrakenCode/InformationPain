{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ID3 import ID3\n",
    "from Neural_Network import Network\n",
    "from Naive_Bayes import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### make_classification notes:\n",
    "# n_samples : default=100\n",
    "# n_features : default=20\n",
    "\n",
    "### n_classes * n_clusters_per_class must be smaller or equal 2 ** n_informative\n",
    "# n_informative : default=2\n",
    "# n_classes : default=2\n",
    "# n_clusters_per_class : default=2\n",
    "\n",
    "# n_redundant : default=2\n",
    "# n_repeated : default=0\n",
    "\n",
    "# A higher class_sep makes the classification task easier\n",
    "# class_sep : default=1.0\n",
    "\n",
    "\n",
    "\n",
    "# to decrease training time I lowered the samples to 1000\n",
    "features, labels = make_classification(n_samples=1000, n_classes=3, n_informative=20,\n",
    "                                       n_features=30, class_sep=1.5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "\n",
    "sk_dtc = DecisionTreeClassifier(criterion='entropy')\n",
    "sk_gausNB = GaussianNB()\n",
    "sk_mlpc = MLPClassifier(activation='logistic'\n",
    "                        , hidden_layer_sizes=(15, 15)\n",
    "                        , learning_rate='constant'\n",
    "                        , learning_rate_init=0.001\n",
    "                        , max_iter=5000)\n",
    "\n",
    "id3 = ID3()\n",
    "naive_bayes = NaiveBayesClassifier()\n",
    "\n",
    "# 30 feature neurons, 2 hidden layers with 15 neurons each, 3 output neurons\n",
    "# for now when we use relu our accuracy is very bad,\n",
    "# we believe something is dying somewhere. We couldn't find the bug after we refactored our NN's code\n",
    "neuralnet = Network(layer_structures=[30, 15, 15, 3], iterations=5000)\n",
    "\n",
    "labels_true = []\n",
    "\n",
    "sk_dtc_predicted = []\n",
    "sk_gausNB_predicted = []\n",
    "sk_mlpc_predicted = []\n",
    "\n",
    "id3_predicted = []\n",
    "naive_bayes_predicted = []\n",
    "neuralnet_predicted = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [03:43<00:00, 20.38s/it]\n"
     ]
    }
   ],
   "source": [
    "# train with numerical data\n",
    "\n",
    "bar = tqdm(total=10)\n",
    "\n",
    "# this loop may take a little bit, It's training 6 models 10 times...\n",
    "# for speeds shake I lowered the number of samples to 1000, takes about 4 minutes\n",
    "# tqdm will give you the average time for each loop\n",
    "for train_index, test_index in kf.split(features):\n",
    "    features_train, features_test = features[train_index], features[test_index]\n",
    "    labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    # save all the of test labels\n",
    "    labels_true.extend(labels_test)\n",
    "    \n",
    "    # convert labels to one hots for the neural network\n",
    "    # features are numeric, so they don't have to be converted\n",
    "    labels_train_one_hot = pd.get_dummies(labels_train).as_matrix()\n",
    "    \n",
    "    # train models\n",
    "    # note that fit() deletes prior training and starts fresh\n",
    "    sk_dtc.fit(features_train, labels_train)\n",
    "    sk_gausNB.fit(features_train, labels_train)\n",
    "    sk_mlpc.fit(features_train, labels_train)\n",
    "    \n",
    "    id3.fit(features_train, labels_train)\n",
    "    naive_bayes.fit(features_train, labels_train)\n",
    "    neuralnet.fit(features_train, labels_train_one_hot)\n",
    "    \n",
    "        \n",
    "    # get predictions\n",
    "    sk_dtc_predicted.extend(sk_dtc.predict(features_test))\n",
    "    sk_gausNB_predicted.extend(sk_gausNB.predict(features_test))\n",
    "    sk_mlpc_predicted.extend(sk_mlpc.predict(features_test))\n",
    "    \n",
    "    id3_predicted.extend(id3.predict(features_test))\n",
    "    naive_bayes_predicted.extend(naive_bayes.predict(features_test))\n",
    "    neuralnet_predicted.extend(neuralnet.predict(features_test, classification=True))\n",
    "    \n",
    "    \n",
    "    bar.update()\n",
    "\n",
    "\n",
    "\n",
    "bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn.tree.DecisionTreeClassifier:\n",
      "Accuracy: 0.71\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.74      0.73       336\n",
      "          1       0.72      0.72      0.72       328\n",
      "          2       0.68      0.67      0.67       336\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1000\n",
      "\n",
      "\n",
      "\n",
      "sklearn.naive_bayes.GaussianNB:\n",
      "Accuracy: 0.85\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.88      0.88       336\n",
      "          1       0.84      0.91      0.87       328\n",
      "          2       0.83      0.77      0.80       336\n",
      "\n",
      "avg / total       0.85      0.85      0.85      1000\n",
      "\n",
      "\n",
      "\n",
      "sklearn.neural_network.MLPClassifier:\n",
      "Accuracy: 0.90\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.92      0.92       336\n",
      "          1       0.90      0.91      0.90       328\n",
      "          2       0.88      0.86      0.87       336\n",
      "\n",
      "avg / total       0.90      0.90      0.90      1000\n",
      "\n",
      "\n",
      "\n",
      "Our ID3 Decision Tree:\n",
      "Accuracy: 0.71\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.73      0.73       336\n",
      "          1       0.73      0.72      0.72       328\n",
      "          2       0.67      0.68      0.68       336\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1000\n",
      "\n",
      "\n",
      "\n",
      "Our Naive Bayes:\n",
      "Accuracy: 0.82\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.91      0.85       336\n",
      "          1       0.85      0.84      0.85       328\n",
      "          2       0.81      0.72      0.76       336\n",
      "\n",
      "avg / total       0.82      0.82      0.82      1000\n",
      "\n",
      "\n",
      "\n",
      "Our Neural Network:\n",
      "Accuracy: 0.82\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.85      0.86       336\n",
      "          1       0.82      0.83      0.82       328\n",
      "          2       0.77      0.78      0.77       336\n",
      "\n",
      "avg / total       0.82      0.82      0.82      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('sklearn.tree.DecisionTreeClassifier:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(labels_true, sk_dtc_predicted)))\n",
    "print(classification_report(labels_true, sk_dtc_predicted))\n",
    "\n",
    "print('\\n\\nsklearn.naive_bayes.GaussianNB:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(labels_true, sk_gausNB_predicted)))\n",
    "print(classification_report(labels_true, sk_gausNB_predicted))\n",
    "\n",
    "print('\\n\\nsklearn.neural_network.MLPClassifier:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(labels_true, sk_mlpc_predicted)))\n",
    "print(classification_report(labels_true, sk_mlpc_predicted))\n",
    "\n",
    "\n",
    "print('\\n\\nOur ID3 Decision Tree:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(labels_true, id3_predicted)))\n",
    "print(classification_report(labels_true, id3_predicted))\n",
    "\n",
    "print('\\n\\nOur Naive Bayes:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(labels_true, naive_bayes_predicted)))\n",
    "print(classification_report(labels_true, naive_bayes_predicted))\n",
    "\n",
    "print('\\n\\nOur Neural Network:')\n",
    "print('Accuracy: {:.2f}'.format(accuracy_score(labels_true, neuralnet_predicted)))\n",
    "print(classification_report(labels_true, neuralnet_predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
