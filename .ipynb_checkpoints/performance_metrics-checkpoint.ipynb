{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification, load_wine\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ID3 import ID3\n",
    "from Neural_Network import Network, relu\n",
    "from Naive_Bayes import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### make_classification notes:\n",
    "# n_samples : default=100\n",
    "# n_features : default=20\n",
    "\n",
    "### n_classes * n_clusters_per_class must be smaller or equal 2 ** n_informative\n",
    "# n_informative : default=2\n",
    "# n_classes : default=2\n",
    "# n_clusters_per_class : default=2\n",
    "\n",
    "# n_redundant : default=2\n",
    "# n_repeated : default=0\n",
    "\n",
    "# A higher class_sep makes the classification task easier\n",
    "# class_sep : default=1.0\n",
    "\n",
    "\n",
    "features, labels = make_classification(n_samples=1000, n_classes=3, n_informative=35\n",
    "                                        , n_features=40, class_sep=1.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_size default is 25% of given list\n",
    "\n",
    "# features_train, features_test, labels_train, labels_test = train_test_split(features, labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # sklearn's decision tree\n",
    "# dtc = DecisionTreeClassifier()\n",
    "# dtc = dtc.fit(features_train, labels_train)\n",
    "# dtc_prediction = dtc.predict(features_test)\n",
    "# print('skearn.tree.DecisionTreeClassifier:')\n",
    "# print(classification_report(labels_test, dtc_prediction))\n",
    "\n",
    "# # our ID3 decision tree\n",
    "# id3 = ID3()\n",
    "# id3.fit(features_train, labels_train)\n",
    "# predictions = id3.predict(features_test)\n",
    "# print('\\n\\nOur ID3 Decision Tree:')\n",
    "# print(classification_report(labels_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # sklearns naive bayes\n",
    "# gausNB = GaussianNB()\n",
    "# gausNB.fit(features_train, labels_train)\n",
    "# gausNB_prediction = gausNB.predict(features_test)\n",
    "# print('sklearn.naive_bayes.GaussianNB')\n",
    "# print(classification_report(labels_test, gausNB_prediction))\n",
    "\n",
    "\n",
    "# # nbc = NaiveBayesClassifier()\n",
    "# # nbc.fit(features_train, labels_train)\n",
    "# # nbc_prediction = nbc.predict(features_test)\n",
    "# # print(classification_report(labels_test, nbc_prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels_train_one_hot = pd.get_dummies(labels_train).as_matrix()\n",
    "\n",
    "# neuralnet = Network(layer_structures=[40, 10, 10, 3], activation_function=relu) \n",
    "# neuralnet.fit(features_train, labels_train_one_hot, iterations=5000)\n",
    "# neuralnet_prediction = neuralnet.predict(features_test, classification=True)\n",
    "\n",
    "# print(classification_report(labels_test, netbc_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af67d9d9c504e459eb448646d89f449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=10), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "skearn.tree.DecisionTreeClassifier:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.53      0.47      0.50       333\n",
      "          1       0.51      0.54      0.52       336\n",
      "          2       0.49      0.51      0.50       331\n",
      "\n",
      "avg / total       0.51      0.51      0.51      1000\n",
      "\n",
      "\n",
      "\n",
      "Our ID3 Decision Tree:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.55      0.53      0.54       333\n",
      "          1       0.54      0.55      0.54       336\n",
      "          2       0.55      0.56      0.55       331\n",
      "\n",
      "avg / total       0.55      0.55      0.55      1000\n",
      "\n",
      "\n",
      "\n",
      "sklearn.naive_bayes.GaussianNB:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.70      0.68       333\n",
      "          1       0.67      0.69      0.68       336\n",
      "          2       0.69      0.63      0.66       331\n",
      "\n",
      "avg / total       0.67      0.67      0.67      1000\n",
      "\n",
      "\n",
      "\n",
      "Our Neural Network:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.60      0.59      0.60       333\n",
      "          1       0.60      0.58      0.59       336\n",
      "          2       0.53      0.54      0.54       331\n",
      "\n",
      "avg / total       0.57      0.57      0.57      1000\n",
      "\n",
      "\n",
      "\n",
      "sklearn.neural_network.MLPClassifier:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.75      0.75       333\n",
      "          1       0.71      0.71      0.71       336\n",
      "          2       0.73      0.73      0.73       331\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "\n",
    "sk_dtc = DecisionTreeClassifier(criterion='entropy')\n",
    "gausNB = GaussianNB()\n",
    "id3 = ID3()\n",
    "# neuralnet = Network(layer_structures=[40, 10, 10, 3], activation_function=relu)\n",
    "mlpc = MLPClassifier(activation='relu', hidden_layer_sizes=(10, 10), learning_rate='constant',\n",
    "           learning_rate_init=0.001, max_iter=5000)\n",
    "\n",
    "\n",
    "labels_true = []\n",
    "\n",
    "sk_dtc_predicted = []\n",
    "id3_predicted = []\n",
    "gausNB_predicted = []\n",
    "neuralnet_predicted = []\n",
    "mlpc_predicted = []\n",
    "\n",
    "\n",
    "bar = tqdm_notebook(total=10)\n",
    "\n",
    "for train_index, test_index in kf.split(features):\n",
    "    features_train, features_test = features[train_index], features[test_index]\n",
    "    labels_train, labels_test = labels[train_index], labels[test_index]\n",
    "    \n",
    "    # save all the of test labels\n",
    "    labels_true.extend(labels_test)\n",
    "    \n",
    "    # convert labels to one hots for the neural network\n",
    "    labels_train_one_hot = pd.get_dummies(labels_train).as_matrix()\n",
    "    \n",
    "    # recreate Neural Network\n",
    "    neuralnet = Network(layer_structures=[40, 10, 10, 3], activation_function=relu)\n",
    "    \n",
    "    # train models\n",
    "    sk_dtc.fit(features_train, labels_train)\n",
    "    id3.fit(features_train, labels_train)\n",
    "    gausNB.fit(features_train, labels_train)\n",
    "    neuralnet.fit(features_train, labels_train_one_hot, iterations=5000)\n",
    "    mlpc.fit(features_train, labels_train)\n",
    "     \n",
    "        \n",
    "    # get predictions\n",
    "    sk_dtc_predicted.extend(sk_dtc.predict(features_test))\n",
    "    id3_predicted.extend(id3.predict(features_test))\n",
    "    gausNB_predicted.extend(gausNB.predict(features_test))\n",
    "    neuralnet_predicted.extend(neuralnet.predict(features_test, classification=True))\n",
    "    mlpc_predicted.extend(mlpc.predict(features_test))\n",
    "    \n",
    "    bar.update()\n",
    "\n",
    "\n",
    "\n",
    "bar.close()\n",
    "    \n",
    "\n",
    "print('sklearn.tree.DecisionTreeClassifier:')\n",
    "print(classification_report(labels_true, sk_dtc_predicted))\n",
    "\n",
    "\n",
    "print('\\n\\nOur ID3 Decision Tree:')\n",
    "print(classification_report(labels_true, id3_predicted))\n",
    "\n",
    "\n",
    "print('\\n\\nsklearn.naive_bayes.GaussianNB:')\n",
    "print(classification_report(labels_true, gausNB_predicted))\n",
    "\n",
    "\n",
    "print('\\n\\nOur Neural Network:')\n",
    "print(classification_report(labels_true, neuralnet_predicted))\n",
    "\n",
    "\n",
    "print('\\n\\nsklearn.neural_network.MLPClassifier:')\n",
    "print(classification_report(labels_true, mlpc_predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
